{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torch.nn as nn\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "from qiskit.tools.monitor import job_monitor\r\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\r\n",
    "from qiskit import Aer, execute, IBMQ\r\n",
    "from qiskit.extensions import XGate, UnitaryGate\r\n",
    "import shutil\r\n",
    "import os\r\n",
    "import time\r\n",
    "import sys\r\n",
    "import functools\r\n",
    "import pandas\r\n",
    "\r\n",
    "# from lib.utils import *\r\n",
    "from lib.U_layer import *\r\n",
    "from lib.P_layer import *\r\n",
    "\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "# account = q.IBMQ.load_account()\r\n",
    "\r\n",
    "print = functools.partial(print, flush=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "interest_num = [3,6]\r\n",
    "ori_img_size = 28\r\n",
    "img_size = 4\r\n",
    "# number of subprocesses to use for data loading\r\n",
    "num_workers = 0\r\n",
    "# how many samples per batch to load\r\n",
    "batch_size = 1\r\n",
    "inference_batch_size = 1\r\n",
    "data_path = './data'\r\n",
    "\r\n",
    "qc_shots = 8192"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# convert data to torch.FloatTensor\r\n",
    "transform = transforms.Compose([transforms.Resize((ori_img_size,ori_img_size)),\r\n",
    "                                transforms.ToTensor()])\r\n",
    "# Path to MNIST Dataset\r\n",
    "train_data = datasets.MNIST(root=data_path, train=True,\r\n",
    "                                   download=True, transform=transform)\r\n",
    "test_data = datasets.MNIST(root=data_path, train=False,\r\n",
    "                                  download=True, transform=transform)\r\n",
    "\r\n",
    "train_data = select_num(train_data,interest_num)\r\n",
    "test_data =  select_num(test_data,interest_num)\r\n",
    "\r\n",
    "# prepare data loaders\r\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\r\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\r\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \r\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Model initialization\r\n",
    "weight_1_1 = torch.tensor([1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,    1.,  1.])\r\n",
    "weight_1_2 = torch.tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.,-1., -1.])\r\n",
    "\r\n",
    "weight_2_1 = torch.tensor([1.,  -1.])\r\n",
    "norm_flag_1 = True\r\n",
    "norm_para_1 = torch.tensor(0.3060)\r\n",
    "\r\n",
    "weight_2_2 = torch.tensor([-1.,  -1.])\r\n",
    "norm_flag_2 = False\r\n",
    "norm_para_2 = torch.tensor(0.6940)\r\n",
    "\r\n",
    "weights = [weight_1_1, weight_1_2, weight_2_1, weight_2_2]\r\n",
    "flags = [norm_flag_1, norm_flag_2]\r\n",
    "params = [norm_para_1, norm_para_2]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# One test sample"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# # Use the first image from test loader as example\r\n",
    "# for batch_idx, (data, target) in enumerate(test_loader):\r\n",
    "#     torch.set_printoptions(threshold=sys.maxsize)\r\n",
    "#     print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\r\n",
    "#     quantum_matrix,qantum_data = data_pre_pro(torchvision.utils.make_grid(data), img_size)\r\n",
    "#     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# p_circ = p_circ_gen(quantum_matrix, weights, flags, params)\r\n",
    "# u_circ = u_circ_gen(quantum_matrix, weights, flags, params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# # Quantum simulation\r\n",
    "\r\n",
    "# # Non-Optimized one\r\n",
    "# qc_shots = 8192\r\n",
    "# counts = fire_ibmq(p_circ, qc_shots, Simulation=True)\r\n",
    "# (mycount, bits) = analyze(counts)\r\n",
    "# class_prob = []\r\n",
    "# for b in range(bits):\r\n",
    "#     class_prob.append(float(mycount[b])/qc_shots)\r\n",
    "\r\n",
    "# print(\"=\"*10, \"Non-Optimized Circuit\", \"=\"*10)\r\n",
    "# print(\"Non-Optimized Circuit Depth:\", p_circ.depth())\r\n",
    "# print(\"Result of non-optimized QC:\", class_prob)\r\n",
    "# print(\"Prediction class: {}\".format(class_prob.index(max(class_prob))))\r\n",
    "# print(\"Target class: {}\".format(target[0]))\r\n",
    "# if class_prob.index(max(class_prob)) == target[0]:\r\n",
    "#     print(\"Correct prediction\")\r\n",
    "# else:\r\n",
    "#     print(\"Incorrect prediction\")\r\n",
    "\r\n",
    "# print(\"=\"*30)\r\n",
    "\r\n",
    "# # Optimized one\r\n",
    "# qc_shots = 8192\r\n",
    "# opt_counts = fire_ibmq(u_circ, qc_shots, Simulation=True)\r\n",
    "# (opt_mycount, bits) = analyze(opt_counts)\r\n",
    "# opt_class_prob = []\r\n",
    "# for b in range(bits):\r\n",
    "#     opt_class_prob.append(float(opt_mycount[b])/qc_shots)\r\n",
    "\r\n",
    "\r\n",
    "# print(\"=\"*10, \"Optimized Circuit\", \"=\"*10)\r\n",
    "# print(\"Optimized Circuit Depth:\", u_circ.depth())\r\n",
    "# print(\"Result of optimized QC:\", opt_class_prob)\r\n",
    "# print(\"Prediction class: {}\".format(opt_class_prob.index(max(opt_class_prob))))\r\n",
    "# print(\"Target class: {}\".format(target[0]))\r\n",
    "# if opt_class_prob.index(max(opt_class_prob)) == target[0]:\r\n",
    "#     print(\"Correct prediction\")\r\n",
    "# else:\r\n",
    "#     print(\"Incorrect prediction\")\r\n",
    "\r\n",
    "# print(\"=\"*30)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "itr = 0\r\n",
    "quiet = True\r\n",
    "simulation = True\r\n",
    "# results = np.zeros(len(test_loader) * batch_size)\r\n",
    "\r\n",
    "p_pred = []\r\n",
    "u_pred = []\r\n",
    "\r\n",
    "p_prob = []\r\n",
    "u_prob = []\r\n",
    "\r\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\r\n",
    "\r\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\r\n",
    "    # print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\r\n",
    "    quantum_matrix, qantum_data = data_pre_pro(\r\n",
    "        torchvision.utils.make_grid(data), img_size, verbose=False)\r\n",
    "\r\n",
    "    p_circ = p_circ_gen(quantum_matrix, weights, flags, params)\r\n",
    "    u_circ = u_circ_gen(quantum_matrix, weights, flags, params)\r\n",
    "\r\n",
    "    # p_circ\r\n",
    "    counts = fire_ibmq(p_circ, qc_shots, Simulation=simulation, quiet=quiet)\r\n",
    "    (mycount, bits) = analyze(counts)\r\n",
    "    class_prob = []\r\n",
    "    for b in range(bits):\r\n",
    "        class_prob.append(float(mycount[b])/qc_shots)\r\n",
    "    \r\n",
    "    p_prob.append(class_prob)\r\n",
    "    result = abs((class_prob.index(max(class_prob)) - target[0]).numpy()) # 0 if correct, 1 if not\r\n",
    "    p_pred.append(result)\r\n",
    "\r\n",
    "    if quiet==False:\r\n",
    "        # print(\"=\"*10, \"Non-Optimized Circuit\", \"=\"*10)\r\n",
    "        # print(\"Non-Optimized Circuit Depth:\", p_circ.depth())\r\n",
    "        # print(\"Result of non-optimized QC:\", class_prob)\r\n",
    "        # print(\"Prediction class: {}\".format(class_prob.index(max(class_prob))))\r\n",
    "        # print(\"Target class: {}\".format(target[0]))\r\n",
    "\r\n",
    "        # if class_prob.index(max(class_prob)) == target[0]:\r\n",
    "        #     print(\"Correct prediction\")\r\n",
    "        # else:\r\n",
    "        #     print(\"Incorrect prediction\")\r\n",
    "\r\n",
    "        print(\"=\"*30)\r\n",
    "\r\n",
    "    # u_circ\r\n",
    "    opt_counts = fire_ibmq(u_circ, qc_shots, Simulation=simulation, quiet=quiet)\r\n",
    "    (opt_mycount, bits) = analyze(opt_counts)\r\n",
    "    opt_class_prob = []\r\n",
    "    for b in range(bits):\r\n",
    "        opt_class_prob.append(float(opt_mycount[b])/qc_shots)\r\n",
    "\r\n",
    "    u_prob.append(opt_class_prob)\r\n",
    "    result = abs((opt_class_prob.index(max(opt_class_prob)) - target[0]).numpy())\r\n",
    "    u_pred.append(result)\r\n",
    "\r\n",
    "    if quiet==False:\r\n",
    "        # print(\"=\"*10, \"Optimized Circuit\", \"=\"*10)\r\n",
    "        # print(\"Optimized Circuit Depth:\", u_circ.depth())\r\n",
    "        # print(\"Result of optimized QC:\", opt_class_prob)\r\n",
    "        # print(\"Prediction class: {}\".format(opt_class_prob.index(max(opt_class_prob))))\r\n",
    "        # print(\"Target class: {}\".format(target[0]))\r\n",
    "\r\n",
    "        # if opt_class_prob.index(max(opt_class_prob)) == target[0]:\r\n",
    "        #     print(\"Correct prediction\")\r\n",
    "        # else:\r\n",
    "        #     print(\"Incorrect prediction\")\r\n",
    "\r\n",
    "        print(\"=\"*30)\r\n",
    "    \r\n",
    "    itr += 1\r\n",
    "    if itr % 100 == 0:\r\n",
    "        print(\"iteration \"+itr)\r\n",
    "        \r\n",
    "df_pred = pd.DataFrame([p_pred, u_pred])\r\n",
    "df_pred.to_csv('./results/test2.csv', index=False)\r\n",
    "\r\n",
    "dfp_prob = pd.DataFrame(p_prob, columns=[\"p[0]\", \"p[1]\"])\r\n",
    "dfu_prob = pd.DataFrame(u_prob, columns=[\"u[0]\", \"u[1]\"])\r\n",
    "\r\n",
    "df_prob = pd.concat([dfp, dfu], axis=1)\r\n",
    "df.to_csv('./results/test.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df_pred = pd.read_csv('./results/pred.csv')\r\n",
    "p_pred = df.iloc[0, :].values.tolist()\r\n",
    "u_pred = df.iloc[1, :].values.tolist()\r\n",
    "\r\n",
    "df_prob = pd.read_csv('./results/test.csv')\r\n",
    "p_prob = df.iloc[:, 0:2].values.tolist()\r\n",
    "u_prob = df.iloc[:, 2:4].values.tolist()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/test2.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-935c937a22b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./results/test2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mp_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mu_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./results/test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/test2.csv'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}