{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torch.nn as nn\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "from qiskit.tools.monitor import job_monitor\r\n",
    "from qiskit import QuantumRegister, QuantumCircuit, ClassicalRegister\r\n",
    "from qiskit import Aer, execute, IBMQ\r\n",
    "from qiskit.extensions import XGate, UnitaryGate\r\n",
    "\r\n",
    "import sys\r\n",
    "import os\r\n",
    "import time\r\n",
    "import functools\r\n",
    "import IPython.display\r\n",
    "\r\n",
    "from lib.utils import *\r\n",
    "from lib.U_layer import *\r\n",
    "from lib.P_layer import *\r\n",
    "\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "print = functools.partial(print, flush=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# account = IBMQ.load_account()\r\n",
    "# provider = IBMQ.get_provider(hub='ibm-q-research', group='uni-cali-la-1', project='main')\r\n",
    "# provider.backends()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<IBMQSimulator('ibmq_qasm_simulator') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmqx2') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_armonk') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_santiago') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_bogota') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_casablanca') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_lima') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_belem') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_quito') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_jakarta') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibmq_manila') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>,\n",
       " <IBMQBackend('ibm_lagos') from IBMQ(hub='ibm-q-research', group='uni-cali-la-1', project='main')>]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "interest_num = [3,6]\r\n",
    "ori_img_size = 28\r\n",
    "img_size = 4\r\n",
    "# number of subprocesses to use for data loading\r\n",
    "num_workers = 0\r\n",
    "# how many samples per batch to load\r\n",
    "batch_size = 1\r\n",
    "inference_batch_size = 1\r\n",
    "data_path = './data'\r\n",
    "\r\n",
    "qc_shots = 8192\r\n",
    "\r\n",
    "\r\n",
    "# convert data to torch.FloatTensor\r\n",
    "transform = transforms.Compose([transforms.Resize((ori_img_size,ori_img_size)),\r\n",
    "                                transforms.ToTensor()])\r\n",
    "# Path to MNIST Dataset\r\n",
    "train_data = datasets.MNIST(root=data_path, train=True,\r\n",
    "                                   download=True, transform=transform)\r\n",
    "test_data = datasets.MNIST(root=data_path, train=False,\r\n",
    "                                  download=True, transform=transform)\r\n",
    "\r\n",
    "train_data = select_num(train_data,interest_num)\r\n",
    "test_data =  select_num(test_data,interest_num)\r\n",
    "\r\n",
    "# prepare data loaders\r\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\r\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\r\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=inference_batch_size, \r\n",
    "    num_workers=num_workers, shuffle=True, drop_last=True)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Model initialization\r\n",
    "weight_1_1 = torch.tensor([1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,    1.,  1.])\r\n",
    "weight_1_2 = torch.tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.,-1., -1.])\r\n",
    "\r\n",
    "weight_2_1 = torch.tensor([1.,  -1.])\r\n",
    "norm_flag_1 = True\r\n",
    "norm_para_1 = torch.tensor(0.3060)\r\n",
    "\r\n",
    "weight_2_2 = torch.tensor([-1.,  -1.])\r\n",
    "norm_flag_2 = False\r\n",
    "norm_para_2 = torch.tensor(0.6940)\r\n",
    "\r\n",
    "weights = [weight_1_1, weight_1_2, weight_2_1, weight_2_2]\r\n",
    "flags = [norm_flag_1, norm_flag_2]\r\n",
    "params = [norm_para_1, norm_para_2]\r\n",
    "\r\n",
    "weights_1 = [weight_1_1, weight_2_1]\r\n",
    "weights_2 = [weight_1_2, weight_2_2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_itr = 2\r\n",
    "saving = False\r\n",
    "quiet = True\r\n",
    "simulation = True\r\n",
    "\r\n",
    "p_pred = []\r\n",
    "u_pred = []\r\n",
    "p_prob = []\r\n",
    "u_prob = []\r\n",
    "itr = 0\r\n",
    "\r\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\r\n",
    "\r\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\r\n",
    "    # print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\r\n",
    "    quantum_matrix, qantum_data = data_pre_pro(\r\n",
    "        torchvision.utils.make_grid(data), img_size, verbose=False)\r\n",
    "\r\n",
    "    p_circ = p_circ_gen(quantum_matrix, weights, flags, params)\r\n",
    "    u_circ = u_circ_gen(quantum_matrix, weights, flags, params)\r\n",
    "\r\n",
    "    # p_circ\r\n",
    "    counts = fire_ibmq(p_circ, qc_shots, Simulation=simulation, quiet=quiet)\r\n",
    "    (mycount, bits) = analyze(counts)\r\n",
    "    class_prob = []\r\n",
    "    for b in range(bits):\r\n",
    "        class_prob.append(float(mycount[b])/qc_shots)\r\n",
    "    \r\n",
    "    p_prob.append(class_prob)\r\n",
    "    result = abs((class_prob.index(max(class_prob)) - target[0]).numpy()) # 0 if correct, 1 if not\r\n",
    "    p_pred.append(result)\r\n",
    "\r\n",
    "    if quiet==False:\r\n",
    "        print(\"=\"*10, \"Non-Optimized Circuit\", \"=\"*10)\r\n",
    "        print(\"Non-Optimized Circuit Depth:\", p_circ.depth())\r\n",
    "        print(\"Result of non-optimized QC:\", class_prob)\r\n",
    "        print(\"Prediction class: {}\".format(class_prob.index(max(class_prob))))\r\n",
    "        print(\"Target class: {}\".format(target[0]))\r\n",
    "\r\n",
    "        if class_prob.index(max(class_prob)) == target[0]:\r\n",
    "            print(\"Correct prediction\")\r\n",
    "        else:\r\n",
    "            print(\"Incorrect prediction\")\r\n",
    "\r\n",
    "        print(\"=\"*30)\r\n",
    "\r\n",
    "    # u_circ\r\n",
    "    opt_counts = fire_ibmq(u_circ, qc_shots, Simulation=simulation, quiet=quiet)\r\n",
    "    (opt_mycount, bits) = analyze(opt_counts)\r\n",
    "    opt_class_prob = []\r\n",
    "    for b in range(bits):\r\n",
    "        opt_class_prob.append(float(opt_mycount[b])/qc_shots)\r\n",
    "\r\n",
    "    u_prob.append(opt_class_prob)\r\n",
    "    result = abs((opt_class_prob.index(max(opt_class_prob)) - target[0]).numpy())\r\n",
    "    u_pred.append(result)\r\n",
    "\r\n",
    "    if quiet==False:\r\n",
    "        print(\"=\"*10, \"Optimized Circuit\", \"=\"*10)\r\n",
    "        print(\"Optimized Circuit Depth:\", u_circ.depth())\r\n",
    "        print(\"Result of optimized QC:\", opt_class_prob)\r\n",
    "        print(\"Prediction class: {}\".format(opt_class_prob.index(max(opt_class_prob))))\r\n",
    "        print(\"Target class: {}\".format(target[0]))\r\n",
    "\r\n",
    "        if opt_class_prob.index(max(opt_class_prob)) == target[0]:\r\n",
    "            print(\"Correct prediction\")\r\n",
    "        else:\r\n",
    "            print(\"Incorrect prediction\")\r\n",
    "\r\n",
    "        print(\"=\"*30)\r\n",
    "    \r\n",
    "    itr += 1\r\n",
    "    IPython.display.clear_output(wait=True)\r\n",
    "    print(\"iterantion\", itr, \"out of\", min(max_itr, len(test_loader)))\r\n",
    "    if itr >= max_itr:\r\n",
    "        break\r\n",
    "\r\n",
    "if saving:\r\n",
    "    t = time.localtime()\r\n",
    "    dir = \"./results/multi_\"+time.strftime('%m-%d_%H-%M', t)\r\n",
    "\r\n",
    "    if not os.path.exists(dir):\r\n",
    "        os.makedirs(dir)\r\n",
    "\r\n",
    "    df_pred = pd.DataFrame([p_pred, u_pred])\r\n",
    "    df_pred.to_csv(dir+\"/predictions.csv\", index=False)\r\n",
    "\r\n",
    "    dfp = pd.DataFrame(p_prob, columns=[\"p[0]\", \"p[1]\"])\r\n",
    "    dfu = pd.DataFrame(u_prob, columns=[\"u[0]\", \"u[1]\"])\r\n",
    "    df_prob = pd.concat([dfp, dfu], axis=1)\r\n",
    "    df_pred.to_csv(dir+\"/probilities.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "data_path = \".\\\\results\\\\multi_4x4_full_set\"\r\n",
    "\r\n",
    "df_pred = pd.read_csv(data_path + '\\\\predictions.csv')\r\n",
    "p_pred = df_pred.iloc[0, :].to_numpy()\r\n",
    "u_pred = df_pred.iloc[1, :].to_numpy()\r\n",
    "\r\n",
    "df_prob = pd.read_csv(data_path + '\\\\probabilities.csv')\r\n",
    "p_prob = df_prob.iloc[:, 0:2].to_numpy()\r\n",
    "u_prob = df_prob.iloc[:, 2:4].to_numpy()\r\n",
    "\r\n",
    "p_acc = 1 - p_pred.sum()/p_pred.shape[0]\r\n",
    "u_acc = 1 - u_pred.sum()/u_pred.shape[0]\r\n",
    "\r\n",
    "print(\"p_acc:\", p_acc, '\\n' \"u_acc:\", u_acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "p_acc: 0.9634146341463414 \n",
      "u_acc: 0.9649390243902439\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Single Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "max_itr = 1000\r\n",
    "saving = False\r\n",
    "quiet = True\r\n",
    "simulation = True\r\n",
    "backend = 'ibmq_casablanca'\r\n",
    "\r\n",
    "p_pred = []\r\n",
    "u_pred = []\r\n",
    "p_prob = []\r\n",
    "u_prob = []\r\n",
    "itr = 0\r\n",
    "\r\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\r\n",
    "\r\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\r\n",
    "    # print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\r\n",
    "    quantum_matrix, qantum_data = data_pre_pro(\r\n",
    "        torchvision.utils.make_grid(data), img_size, verbose=False)\r\n",
    "\r\n",
    "    p_single_circ = p_single_circ_gen(quantum_matrix, weights_1, norm_flag_1, norm_para_1)\r\n",
    "    counts = fire_ibmq(p_single_circ, qc_shots, Simulation=simulation, backend_name=backend, quiet=quiet)\r\n",
    "    \r\n",
    "    (mycount, bits) = analyze(counts)\r\n",
    "    class_prob = []\r\n",
    "    for b in range(bits):\r\n",
    "        class_prob.append(float(mycount[b])/qc_shots)\r\n",
    "\r\n",
    "    class_prob.append(1-class_prob[0])\r\n",
    "    result = abs((class_prob.index(max(class_prob)) - target[0]).numpy()) # 0 if correct, 1 if not\r\n",
    "\r\n",
    "    p_prob.append(class_prob)\r\n",
    "    p_pred.append(result)\r\n",
    "\r\n",
    "    # print(result==0, class_prob[0])\r\n",
    "    \r\n",
    "    itr += 1\r\n",
    "    IPython.display.clear_output(wait=True)\r\n",
    "    print(\"iterantion\", itr, \"out of\", min(max_itr, len(test_loader)))\r\n",
    "    if itr >= max_itr:\r\n",
    "        break\r\n",
    "\r\n",
    "if saving:\r\n",
    "    t = time.localtime()\r\n",
    "    dir = \"./results/single_\"+time.strftime('%m-%d_%H-%M', t)\r\n",
    "\r\n",
    "    if not os.path.exists(dir):\r\n",
    "        os.makedirs(dir)\r\n",
    "\r\n",
    "    # df_pred = pd.DataFrame([p_pred, u_pred])\r\n",
    "    df_pred = pd.DataFrame(p_pred)\r\n",
    "    df_pred.to_csv(dir+\"/predictions.csv\", index=False)\r\n",
    "\r\n",
    "    dfp = pd.DataFrame(p_prob, columns=[\"p[0]\", \"p[1]\"])\r\n",
    "    # dfu = pd.DataFrame(u_prob, columns=[\"u[0]\", \"u[1]\"])\r\n",
    "    dfp.to_csv(dir+\"/probilities.csv\", index=False)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iterantion 7 out of 1000\n",
      "Job Status: job is being initialized"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# singular\r\n",
    "data_path = \"results\\\\07-28_18-42_single\"\r\n",
    "\r\n",
    "df_pred = pd.read_csv(data_path + '\\\\predictions.csv')\r\n",
    "p_pred = df_pred.iloc[:, 0].to_numpy()\r\n",
    "\r\n",
    "df_prob = pd.read_csv(data_path + \"\\\\probilities.csv\")\r\n",
    "p_prob = df_prob.iloc[:, 0:2].to_numpy()\r\n",
    "\r\n",
    "p_acc = 1 - p_pred.sum()/p_pred.shape[0]\r\n",
    "print(p_acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.76\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dual Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "max_itr = 2000\r\n",
    "saving = True\r\n",
    "quiet = True\r\n",
    "simulation = True\r\n",
    "\r\n",
    "p_pred = []\r\n",
    "u_pred = []\r\n",
    "p_prob = []\r\n",
    "u_prob = []\r\n",
    "itr = 0\r\n",
    "\r\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\r\n",
    "\r\n",
    "    torch.set_printoptions(threshold=sys.maxsize)\r\n",
    "    # print(\"Batch Id: {}, Target: {}\".format(batch_idx,target))\r\n",
    "    quantum_matrix, qantum_data = data_pre_pro(\r\n",
    "        torchvision.utils.make_grid(data), img_size, verbose=False)\r\n",
    "\r\n",
    "    p_single_circ_1 = p_single_circ_gen(quantum_matrix, weights_1, norm_flag_1, norm_para_1)\r\n",
    "    p_single_circ_2 = p_single_circ_gen(quantum_matrix, weights_2, norm_flag_2, norm_para_2)\r\n",
    "    class_prob = []\r\n",
    "    \r\n",
    "    counts = fire_ibmq(p_single_circ_1, qc_shots, Simulation=simulation, quiet=quiet)\r\n",
    "    (mycount, bits) = analyze(counts)\r\n",
    "    for b in range(bits):\r\n",
    "        class_prob.append(float(mycount[b])/qc_shots)\r\n",
    "    \r\n",
    "    counts = fire_ibmq(p_single_circ_2, qc_shots, Simulation=simulation, quiet=quiet)\r\n",
    "    (mycount, bits) = analyze(counts)\r\n",
    "    for b in range(bits):\r\n",
    "        class_prob.append(float(mycount[b])/qc_shots)\r\n",
    "\r\n",
    "    result = abs((class_prob.index(max(class_prob)) - target[0]).numpy()) # 0 if correct, 1 if not\r\n",
    "\r\n",
    "    p_prob.append(class_prob)\r\n",
    "    p_pred.append(result)\r\n",
    "\r\n",
    "    # print(result==0, class_prob[0])\r\n",
    "    \r\n",
    "    itr += 1\r\n",
    "    IPython.display.clear_output(wait=True)\r\n",
    "    print(\"Iterantion\", itr, \"out of\", min(max_itr, len(test_loader))\r\n",
    "    if itr >= max_itr:\r\n",
    "        break\r\n",
    "\r\n",
    "if saving:\r\n",
    "    t = time.localtime()\r\n",
    "    dir = \"./results/dual_\"+time.strftime('%m-%d_%H-%M', t)\r\n",
    "\r\n",
    "    if not os.path.exists(dir):\r\n",
    "        os.makedirs(dir)\r\n",
    "\r\n",
    "    df_pred = pd.DataFrame(p_pred)\r\n",
    "    df_pred.to_csv(dir+\"/predictions.csv\", index=False)\r\n",
    "\r\n",
    "    df_prob = pd.DataFrame(p_prob, columns=[\"p[0]\", \"p[1]\"])\r\n",
    "    df_prob.to_csv(dir+\"/probilities.csv\", index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iterantion 582 out of 2000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data_path = \"results\\\\dual_07-29_05-28\"\r\n",
    "\r\n",
    "df_pred = pd.read_csv(data_path + '\\\\predictions.csv')\r\n",
    "p_pred = df_pred.iloc[:, 0].to_numpy()\r\n",
    "\r\n",
    "df_prob = pd.read_csv(data_path + \"\\\\probilities.csv\")\r\n",
    "p_prob = df_prob.iloc[:, 0:2].to_numpy()\r\n",
    "\r\n",
    "p_acc = 1 - p_pred.sum()/p_pred.shape[0]\r\n",
    "print(p_acc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7921747967479675\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "max_itr = 99999\r\n",
    "min(max_itr, len(test_loader))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1968"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}